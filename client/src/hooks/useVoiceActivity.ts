/**
 * useVoiceActivity Hook
 * =======================
 * 
 * Voice Activity Detection (VAD) - Ses Aktivite AlgÄ±lama
 * 
 * Bu hook, kullanÄ±cÄ±nÄ±n konuÅŸup konuÅŸmadÄ±ÄŸÄ±nÄ± algÄ±lar.
 * 
 * NasÄ±l Ã‡alÄ±ÅŸÄ±r?
 * --------------
 * 1. AudioContext oluÅŸtur (Web Audio API)
 * 2. Audio stream'i AnalyserNode'a baÄŸla
 * 3. Her frame'de ses seviyesini Ã¶lÃ§
 * 4. EÅŸik deÄŸerin Ã¼stÃ¼ndeyse "konuÅŸuyor" olarak iÅŸaretle
 * 
 * Neden Ã–nemli?
 * -------------
 * - UI'da konuÅŸan kiÅŸiyi vurgulama
 * - Push-to-talk Ã¶zelliÄŸi
 * - Otomatik mikrofon kontrolÃ¼
 * - Daha dÃ¼ÅŸÃ¼k bant geniÅŸliÄŸi (sessizken video kalitesini dÃ¼ÅŸÃ¼rme)
 */

import { useState, useRef, useCallback, useEffect } from 'react';

interface UseVoiceActivityProps {
    stream: MediaStream | null;
    threshold?: number;  // Ses eÅŸiÄŸi (0-255 arasÄ±, varsayÄ±lan: 30)
    smoothingTimeConstant?: number;  // YumuÅŸatma (0-1 arasÄ±, varsayÄ±lan: 0.8)
}

interface UseVoiceActivityReturn {
    isSpeaking: boolean;
    volume: number;  // 0-100 arasÄ± ses seviyesi
    startDetection: () => void;
    stopDetection: () => void;
}

export function useVoiceActivity({
    stream,
    threshold = 30,
    smoothingTimeConstant = 0.8,
}: UseVoiceActivityProps): UseVoiceActivityReturn {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [volume, setVolume] = useState(0);

    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
    const animationFrameRef = useRef<number | null>(null);
    const isRunningRef = useRef(false);

    /**
     * Ses seviyesini analiz et
     */
    const analyzeVolume = useCallback(() => {
        if (!analyserRef.current || !isRunningRef.current) return;

        const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
        analyserRef.current.getByteFrequencyData(dataArray);

        // Ortalama ses seviyesini hesapla
        const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;

        // 0-100 arasÄ±na normalize et
        const normalizedVolume = Math.min(100, Math.round((average / 255) * 100));
        setVolume(normalizedVolume);

        // EÅŸik kontrolÃ¼
        setIsSpeaking(average > threshold);

        // Sonraki frame'i planla
        animationFrameRef.current = requestAnimationFrame(analyzeVolume);
    }, [threshold]);

    /**
     * VAD'Ä± baÅŸlat
     */
    const startDetection = useCallback(() => {
        if (!stream || isRunningRef.current) return;

        try {
            // AudioContext oluÅŸtur
            const audioContext = new AudioContext();
            audioContextRef.current = audioContext;

            // Analyser oluÅŸtur
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;  // Daha hÄ±zlÄ± analiz iÃ§in kÃ¼Ã§Ã¼k FFT
            analyser.smoothingTimeConstant = smoothingTimeConstant;
            analyserRef.current = analyser;

            // Stream'i AudioContext'e baÄŸla
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            sourceRef.current = source;

            // Analizi baÅŸlat
            isRunningRef.current = true;
            analyzeVolume();

            console.log('ðŸŽ¤ VAD baÅŸlatÄ±ldÄ±');
        } catch (error) {
            console.error('âŒ VAD baÅŸlatÄ±lamadÄ±:', error);
        }
    }, [stream, smoothingTimeConstant, analyzeVolume]);

    /**
     * VAD'Ä± durdur
     */
    const stopDetection = useCallback(() => {
        isRunningRef.current = false;

        if (animationFrameRef.current) {
            cancelAnimationFrame(animationFrameRef.current);
            animationFrameRef.current = null;
        }

        if (sourceRef.current) {
            sourceRef.current.disconnect();
            sourceRef.current = null;
        }

        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }

        analyserRef.current = null;
        setIsSpeaking(false);
        setVolume(0);

        console.log('ðŸ›‘ VAD durduruldu');
    }, []);

    // Stream deÄŸiÅŸtiÄŸinde yeniden baÅŸlat
    useEffect(() => {
        if (stream) {
            startDetection();
        }
        return () => {
            stopDetection();
        };
    }, [stream, startDetection, stopDetection]);

    return {
        isSpeaking,
        volume,
        startDetection,
        stopDetection,
    };
}
