/**
 * useVoiceActivity Hook
 * =======================
 * 
 * Voice Activity Detection (VAD) - Ses Aktivite AlgÄ±lama
 * 
 * Bu hook, kullanÄ±cÄ±nÄ±n konuÅŸup konuÅŸmadÄ±ÄŸÄ±nÄ± algÄ±lar.
 * 
 * NasÄ±l Ã‡alÄ±ÅŸÄ±r?
 * --------------
 * 1. AudioContext oluÅŸtur (Web Audio API)
 * 2. Audio stream'i AnalyserNode'a baÄŸla
 * 3. Her frame'de ses seviyesini Ã¶lÃ§
 * 4. EÅŸik deÄŸerin Ã¼stÃ¼ndeyse "konuÅŸuyor" olarak iÅŸaretle
 * 
 * Neden Ã–nemli?
 * -------------
 * - UI'da konuÅŸan kiÅŸiyi vurgulama
 * - Push-to-talk Ã¶zelliÄŸi
 * - Otomatik mikrofon kontrolÃ¼
 * - Daha dÃ¼ÅŸÃ¼k bant geniÅŸliÄŸi (sessizken video kalitesini dÃ¼ÅŸÃ¼rme)
 */

import { useState, useRef, useCallback, useEffect } from 'react';

interface UseVoiceActivityProps {
    stream: MediaStream | null;
    threshold?: number;  // Ses eÅŸiÄŸi (0-255 arasÄ±, varsayÄ±lan: 30)
    smoothingTimeConstant?: number;  // YumuÅŸatma (0-1 arasÄ±, varsayÄ±lan: 0.8)
}

interface UseVoiceActivityReturn {
    isSpeaking: boolean;
    volume: number;  // 0-100 arasÄ± ses seviyesi
    startDetection: () => void;
    stopDetection: () => void;
}

export function useVoiceActivity({
    stream,
    threshold = 10,              // Daha hassas (FÄ±sÄ±ltÄ±yÄ± bile algÄ±lar)
    smoothingTimeConstant = 0.02, // Ã‡ok daha hÄ±zlÄ± tepki (Kelimelerin baÅŸÄ±nÄ± yutmamasÄ± iÃ§in)
}: UseVoiceActivityProps): UseVoiceActivityReturn {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [volume, setVolume] = useState(0);

    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
    const intervalRef = useRef<ReturnType<typeof setInterval> | null>(null);

    /**
     * VAD'Ä± baÅŸlat
     */
    const startDetection = useCallback(() => {
        if (!stream || intervalRef.current) return;

        try {
            // AudioContext oluÅŸtur
            const audioContext = new AudioContext();
            audioContextRef.current = audioContext;

            // Analyser oluÅŸtur
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;  // Daha hÄ±zlÄ± analiz iÃ§in kÃ¼Ã§Ã¼k FFT
            analyser.smoothingTimeConstant = smoothingTimeConstant;
            analyserRef.current = analyser;

            // Stream'i AudioContext'e baÄŸla
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            sourceRef.current = source;

            // Analiz fonksiyonu - closure'da analyser'Ä± yakala
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            let lastSpeechTime = 0;
            const HOLD_TIME = 500; // 500ms hold time

            const analyze = () => {
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
                const normalizedVolume = Math.min(100, Math.round((average / 255) * 100));
                setVolume(normalizedVolume);

                const now = Date.now();
                if (average > threshold) {
                    setIsSpeaking(true);
                    lastSpeechTime = now;
                } else {
                    // Sessizlik sÃ¼resi HOLD_TIME'Ä± geÃ§tiyse kapat
                    if (now - lastSpeechTime > HOLD_TIME) {
                        setIsSpeaking(false);
                    }
                }
            };

            // Analizi setInterval ile baÅŸlat
            // 20ms = 50 fps (Daha sÄ±k kontrol, daha hÄ±zlÄ± aÃ§Ä±lÄ±ÅŸ)
            intervalRef.current = setInterval(analyze, 20);

            console.log('ğŸ¤ VAD baÅŸlatÄ±ldÄ±');
        } catch (error) {
            console.error('âŒ VAD baÅŸlatÄ±lamadÄ±:', error);
        }
    }, [stream, smoothingTimeConstant, threshold]);

    /**
     * VAD'Ä± durdur
     */
    const stopDetection = useCallback(() => {
        if (intervalRef.current) {
            clearInterval(intervalRef.current);
            intervalRef.current = null;
        }

        if (sourceRef.current) {
            sourceRef.current.disconnect();
            sourceRef.current = null;
        }

        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }

        analyserRef.current = null;
        setIsSpeaking(false);
        setVolume(0);

        console.log('ğŸ›‘ VAD durduruldu');
    }, []);

    // Stream deÄŸiÅŸtiÄŸinde yeniden baÅŸlat
    useEffect(() => {
        if (stream) {
            startDetection();
        }
        return () => {
            stopDetection();
        };
    }, [stream, startDetection, stopDetection]);

    return {
        isSpeaking,
        volume,
        startDetection,
        stopDetection,
    };
}
